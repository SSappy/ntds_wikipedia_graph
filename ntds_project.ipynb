{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to acquire a sub-network of the Wikipedia hyperlink network. In such a graph, each node is a Wikipedia page and there is a link between node a and node b is there is a link to page b on page a. This is a directed network but we will make it undirected later on.\n",
    "\n",
    "The process of the acquisition is the following : \n",
    "* Start from an arbitrary root node (prefer and ambiguous page in order to get as many different communities as possible).\n",
    "* Explore the page to get the intra-wiki links and get first nodes.\n",
    "* For each first node, explore the intra-wiki links to get the second nodes.\n",
    "\n",
    "We chose to scrap directly the HTML code of wikipedia pages rather than using the standard Wikipedia API because this API cannot fetch disambiguation pages natively and those are some pages we are interrested in as the list a large variety of links (more on that later). \n",
    "\n",
    "Moreover, scraping the HTML code of pages is really easy and straigtforward when we are simply looking for intra wiki links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Wikipedia pages, all the links are contained in the following HTML structure of tags: \n",
    "```html\n",
    "<li>\n",
    "    <a href:''>\n",
    "    </a>\n",
    "</li>\n",
    "```\n",
    "This is what is used in the following function that finds the intra Wiki links on a given page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inner_links(page_link):\n",
    "    \"\"\"\n",
    "    :param page_link: url of the current page\n",
    "    :return: list of the intra wiki urls contained in the current page\n",
    "    \"\"\"\n",
    "    links = []\n",
    "    # Get the HTML code of the page.\n",
    "    soup = BeautifulSoup(requests.get('https://en.wikipedia.org'+page_link).text)\n",
    "    # Look for all the <li> tags contained in the page.\n",
    "    li_tags = soup.find_all('li')  \n",
    "    for li_tag in li_tags:\n",
    "        # Look for all the <li> tags contained the current <a> tag.\n",
    "        a_tags = li_tag.find_all('a')\n",
    "        for a_tag in a_tags:\n",
    "            try:\n",
    "                # Check if the current <a> tag is an intra wiki link.\n",
    "                if '/wiki/' == a_tag['href'][0:6]:\n",
    "                    links.append(a_tag['href'])\n",
    "            except KeyError:\n",
    "                # In this case the <a> tag is not a link.\n",
    "                pass\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use as `root_node` the disambiguation page [Jaguar](https://en.wikipedia.org/wiki/Jaguar_(disambiguation) as it lists a really wide variety of themes (animals, cars, music, films, weapons...). The aim is to scrap pages from as many different communities as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node = '/wiki/Jaguar_(disambiguation)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = {}  # This dict stores for each page the list of its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_nodes = set(find_inner_links(root_node))\n",
    "neighbors[root_node] = first_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_nodes = set()\n",
    "for link in first_nodes:\n",
    "    tmp = find_inner_links(link)\n",
    "    neighbors[link] = tmp\n",
    "    second_nodes = second_nodes.union(set(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the set of all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = first_nodes.union(second_nodes)\n",
    "nodes.add(origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for connections between second nodes and the rest of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for link in second_nodes:\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print('{}/{}'.format(counter, len(second_nodes)))\n",
    "    tmp = find_inner_links(link)\n",
    "    neighbors[link] = list(set(tmp).intersection(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating pickle files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the scraping of the network takes quite some time (especially getting the inner connections), we store the results in pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(nodes, 'nodes')\n",
    "save_obj(first_nodes, 'first_nodes')\n",
    "save_obj(second_nodes, 'second_nodes')\n",
    "save_obj(neighbors, 'neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = load_obj('nodes')\n",
    "first_nodes = load_obj('first_nodes')\n",
    "second_nodes = load_obj('second_nodes')\n",
    "neighbors = load_obj('neighbors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network creation\n",
    "\n",
    "Let's convert the collected network into a networkx instance which is quite handy to manipulate.\n",
    "\n",
    "Let's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(nodes)\n",
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directed :\n",
    "#g = nx.DiGraph(neighbors)\n",
    "\n",
    "#undirected :\n",
    "g = nx.Graph(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = nx.adjacency_matrix(g)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(nx.laplacian_matrix(g), precision=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if it's symmetric :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(adj != adj.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = g.edges(nodes[0])\n",
    "edges = list(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_edges = neighbors[nodes[0]]\n",
    "real_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(real_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Exploration\n",
    "\n",
    "In this part of the notebook, we provide some indicators of the data in order to understand what we'll be working on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: properties of the collected network\n",
    "\n",
    "* Adjacency matrix\n",
    "* Degrees distribution\n",
    "* Average degree\n",
    "* Diameter of the collected network\n",
    "* (Pruning the collected network if necessary ?)\n",
    "* Visualization of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_edges = 0\n",
    "for i in neighbors.keys():  # for each node\n",
    "    number_of_edges += len(neighbors[i])  # count the number of neighbors of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of nodes : {}'.format(len(nodes)))\n",
    "print('Number of first nodes : {}'.format(len(first_nodes)))\n",
    "print('Number of second nodes : {}'.format(len(second_nodes)))\n",
    "print('Number of edges : {}'.format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degrees distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = adj.sum(axis=1)\n",
    "\n",
    "plt.hist(degrees, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_truncated = np.array(degrees)\n",
    "\n",
    "degrees_truncated = degrees_truncated[degrees_truncated < 700]\n",
    "\n",
    "plt.hist(degrees_truncated, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(g, node_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = sparse.csr_matrix(nx.laplacian_matrix(g), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = sparse.linalg.eigsh(laplacian, k=10, which='SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = laplacian.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eigenvalues, '.-', markersize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
